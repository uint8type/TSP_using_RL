{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import random\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "\n",
        "# Define the TSP environment\n",
        "class TSPEnvironment:\n",
        "  def __init__(self, num_cities=5):\n",
        "    self.cities = np.random.rand(num_cities, 2)\n",
        "    self.num_cities = len(self.cities)\n",
        "    self.reset()\n",
        "\n",
        "  def reset(self):\n",
        "    self.visited = [False] * self.num_cities\n",
        "    self.current_city = 0\n",
        "    self.total_tour_length = 0\n",
        "\n",
        "  def get_state(self):\n",
        "    state = [int(self.visited[i]) for i in range(self.num_cities)]\n",
        "    return np.array(state)\n",
        "\n",
        "  def step(self, action):\n",
        "    next_city = action\n",
        "    if not self.visited[next_city]:\n",
        "      distance = self._calculate_distance(self.current_city, next_city)\n",
        "      self.total_tour_length += distance\n",
        "      self.current_city = next_city\n",
        "      self.visited[next_city] = True\n",
        "    else:\n",
        "      distance = 0  # Additional negative reward for revisiting the city\n",
        "    done = all(self.visited)\n",
        "    return self.get_state(), -distance, done\n",
        "\n",
        "  def _calculate_distance(self, city1, city2):\n",
        "    x1, y1 = self.cities[city1]\n",
        "    x2, y2 = self.cities[city2]\n",
        "    return np.sqrt((x1 - x2) ** 2 + (y1 - y2) ** 2)"
      ],
      "metadata": {
        "id": "XZcYi7Ldjm-F"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class QLearningAgent:\n",
        "  def __init__(self, num_states, num_actions, learning_rate=0.1, gamma=0.9, exploration_prob=1):\n",
        "    self.num_states = num_states\n",
        "    self.num_actions = num_actions\n",
        "    self.learning_rate = learning_rate\n",
        "    self.gamma = gamma\n",
        "    self.exploration_prob = exploration_prob\n",
        "    self.q_table = np.zeros((num_states, num_actions))\n",
        "\n",
        "  def choose_action(self, state):\n",
        "    if random.random() < self.exploration_prob:\n",
        "      return random.choice(range(self.num_actions))\n",
        "    else:\n",
        "      return np.argmax(self.q_table[state])\n",
        "\n",
        "  def train(self, state, action, reward, next_state, done):\n",
        "    next_q_max = np.max(self.q_table[next_state])\n",
        "    target_q = reward + self.gamma * next_q_max * (1 - done)\n",
        "    self.q_table[state, action] = (1 - self.learning_rate) * self.q_table[state, action] + \\\n",
        "                                  self.learning_rate * target_q\n"
      ],
      "metadata": {
        "id": "xyYEHSKzDmgt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Define a function to plot the tour\n",
        "import matplotlib.pyplot as plt\n",
        "def plot_tour(cities, tour, title):\n",
        "  x = [cities[i][0] for i in tour + [tour[0]]]\n",
        "  y = [cities[i][1] for i in tour + [tour[0]]]\n",
        "  plt.figure(figsize=(4, 4))\n",
        "  plt.plot(x, y, marker='o', linestyle='-')\n",
        "  plt.scatter(x, y, c='red', marker='x')\n",
        "  for i, city in enumerate(cities):\n",
        "    plt.text(city[0] + 0.1, city[1] + 0.1, f\"{i}\", fontsize=10, color='yellow')\n",
        "  plt.title(title)\n",
        "  plt.xlabel(\"X\")\n",
        "  plt.ylabel(\"Y\")\n",
        "  plt.grid(True)\n",
        "  plt.show()"
      ],
      "metadata": {
        "id": "xlhTWPy0kJOQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Main training loop\n",
        "def main():\n",
        "\n",
        "  num_cities = 5\n",
        "  env = TSPEnvironment(num_cities=num_cities)\n",
        "  agent = QLearningAgent(num_states=num_cities, num_actions=num_cities)\n",
        "  num_episodes = 10\n",
        "\n",
        "  for episode in range(num_episodes):\n",
        "    env.reset()\n",
        "    state = env.get_state()\n",
        "    print(state)\n",
        "    done = False\n",
        "    total_reward = 0\n",
        "    tour = []  # Initialize an empty tour for the episode\n",
        "    tour.append(state)\n",
        "    while not all(env.visited[i] for i in range(num_cities)):\n",
        "      action = agent.choose_action(state)\n",
        "      print(action)\n",
        "      next_state, reward, done = env.step(action)\n",
        "      agent.train(state, action, reward, next_state, done)\n",
        "      state = next_state\n",
        "      total_reward = total_reward +  reward\n",
        "\n",
        "      tour.append(env.current_city)\n",
        "      #print(tour)\n",
        "    print(f\"Episode {episode + 1}, Total Tour Length: {total_reward:.2f}\")\n",
        "      #plot_tour(env.cities, tour, f\"Episode {episode + 1}\")\n",
        "      #tour = []\n",
        "    #print(tour)\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "H3wJLwZ1kRL5",
        "outputId": "798f46c1-1704-43b8-baa1-1f26b53b245d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[0 0 0 0 0]\n",
            "2\n",
            "0\n",
            "0\n",
            "2\n",
            "0\n",
            "1\n",
            "2\n",
            "3\n",
            "0\n",
            "2\n",
            "4\n",
            "Episode 1, Total Tour Length: -2.30\n",
            "[0 0 0 0 0]\n",
            "0\n",
            "4\n",
            "3\n",
            "2\n",
            "3\n",
            "4\n",
            "0\n",
            "1\n",
            "Episode 2, Total Tour Length: -2.08\n",
            "[0 0 0 0 0]\n",
            "0\n",
            "3\n",
            "0\n",
            "0\n",
            "3\n",
            "1\n",
            "4\n",
            "1\n",
            "0\n",
            "3\n",
            "2\n",
            "Episode 3, Total Tour Length: -2.72\n",
            "[0 0 0 0 0]\n",
            "4\n",
            "4\n",
            "4\n",
            "4\n",
            "2\n",
            "4\n",
            "1\n",
            "2\n",
            "4\n",
            "4\n",
            "1\n",
            "3\n",
            "4\n",
            "2\n",
            "2\n",
            "0\n",
            "Episode 4, Total Tour Length: -2.78\n",
            "[0 0 0 0 0]\n",
            "1\n",
            "0\n",
            "0\n",
            "1\n",
            "4\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "2\n",
            "4\n",
            "4\n",
            "0\n",
            "2\n",
            "4\n",
            "1\n",
            "1\n",
            "1\n",
            "0\n",
            "0\n",
            "3\n",
            "Episode 5, Total Tour Length: -2.07\n",
            "[0 0 0 0 0]\n",
            "2\n",
            "4\n",
            "3\n",
            "0\n",
            "3\n",
            "0\n",
            "0\n",
            "2\n",
            "2\n",
            "4\n",
            "1\n",
            "Episode 6, Total Tour Length: -2.76\n",
            "[0 0 0 0 0]\n",
            "0\n",
            "0\n",
            "0\n",
            "3\n",
            "3\n",
            "3\n",
            "2\n",
            "4\n",
            "0\n",
            "1\n",
            "Episode 7, Total Tour Length: -2.61\n",
            "[0 0 0 0 0]\n",
            "4\n",
            "3\n",
            "0\n",
            "2\n",
            "0\n",
            "3\n",
            "0\n",
            "1\n",
            "Episode 8, Total Tour Length: -2.64\n",
            "[0 0 0 0 0]\n",
            "3\n",
            "0\n",
            "4\n",
            "2\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "1\n",
            "Episode 9, Total Tour Length: -2.93\n",
            "[0 0 0 0 0]\n",
            "2\n",
            "4\n",
            "3\n",
            "4\n",
            "1\n",
            "4\n",
            "4\n",
            "3\n",
            "1\n",
            "0\n",
            "Episode 10, Total Tour Length: -2.60\n"
          ]
        }
      ]
    }
  ]
}